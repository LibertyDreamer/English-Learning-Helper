<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Neural Network Text-to-Speech</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    .hidden {
      display: none;
    }
    textarea {
      width: 100%;
      font-size: 1em;
    }
    button {
      padding: 10px 20px;
      font-size: 1em;
      margin-top: 10px;
    }
    #download-status {
      margin-top: 10px;
      color: #555;
    }
  </style>
</head>
<body>
  <h1>Neural Network Text-to-Speech</h1>

  <!-- Model selection -->
  <div>
    <label for="model-selection">Select TTS Model: </label>
    <select id="model-selection">
      <option value="VITS-4GB">VITS-4GB</option>
      <!-- You can add more model options if available -->
    </select>
  </div>

  <!-- Text input -->
  <div style="margin-top:10px;">
    <label for="input-text">Enter Text:</label><br>
    <textarea id="input-text" rows="4" placeholder="Type your text here..."></textarea>
  </div>

  <!-- Speak button -->
  <div>
    <button id="speak-btn">Speak</button>
  </div>

  <!-- Status display -->
  <div id="download-status" class="hidden"></div>

  <!-- Audio output -->
  <div style="margin-top:10px;">
    <audio id="audio-output" controls></audio>
  </div>

  <!-- JavaScript module -->
  <script type="module">
    // Import the hypothetical TTS engine
    import * as webtts from "https://esm.run/@mlc-ai/web-tts";

    // Assuming the module has a similar prebuiltAppConfig structure as web-llm:
    const availableModels = webtts.prebuiltAppConfig.model_list.map(m => m.model_id);
    console.log("Available TTS Models:", availableModels);

    // Set the default model from the dropdown
    let selectedModel = document.getElementById("model-selection").value;

    // Create the TTS engine instance (hypothetical MLCTTSEngine)
    const engine = new webtts.MLCTTSEngine();

    // Set a callback to report download/initialization progress
    engine.setInitProgressCallback(report => {
      console.log("Initialization progress:", report.progress);
      const status = document.getElementById("download-status");
      status.textContent = report.text;
      status.classList.remove("hidden");
    });

    // Function to initialize the TTS engine
    async function initializeEngine() {
      selectedModel = document.getElementById("model-selection").value;
      await engine.initialize(selectedModel);
      document.getElementById("download-status").classList.add("hidden");
      console.log("Engine initialized with model:", selectedModel);
    }

    // Initialize engine on page load
    initializeEngine();

    // Function to synthesize speech from text
    async function generateSpeech(text) {
      try {
        // Synthesize returns an ArrayBuffer of audio data (e.g., WAV)
        const audioBuffer = await engine.synthesize(text);
        // Convert the ArrayBuffer into a Blob and create an object URL for the audio element
        const blob = new Blob([audioBuffer], { type: "audio/wav" });
        const url = URL.createObjectURL(blob);
        const audioElement = document.getElementById("audio-output");
        audioElement.src = url;
        audioElement.play();
      } catch (error) {
        console.error("Error during synthesis:", error);
      }
    }

    // When the user clicks the Speak button, generate the speech
    document.getElementById("speak-btn").addEventListener("click", async () => {
      const text = document.getElementById("input-text").value;
      if (text.trim() === "") {
        alert("Please enter some text!");
        return;
      }
      // Reinitialize the engine if needed (e.g., if model selection changed)
      await initializeEngine();
      generateSpeech(text);
    });
  </script>
</body>
</html>
